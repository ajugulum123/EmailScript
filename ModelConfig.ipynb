{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf87f9f3d900b325"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import LinkedInInfo \n",
    "import spacy\n",
    "from LinkedInInfo import fetch_specific_linkedin_info\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:35:13.285438Z",
     "start_time": "2025-04-23T00:35:13.280020Z"
    }
   },
   "id": "37c431f987a45aab",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a58c95719c2e00c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "# Example usage\n",
    "profile_desired = LinkedInInfo.fetch_linkedin_info()\n",
    "recepient_school = fetch_specific_linkedin_info(profile_desired)\n",
    "position_name = fetch_specific_linkedin_info(profile_desired)\n",
    "company_name = fetch_specific_linkedin_info(profile_desired)\n",
    "\n",
    "def generate_email(your_name, your_field, your_university, recepient_name, position_name, company_name, email_type):\n",
    "    \n",
    "    # case for the type of email\n",
    "    if email_type == ('general'):\n",
    "        template = (f'Hi {recepient_name},'\n",
    "                    f'I hope you are doing well! A quick introduction, my name is {your_name} and I am currently a rising senior at {your_university} studying {your_field}. I wanted to reach out because I am interested in the {your_field} field and to learn more about your role & career path at as a {position_name} at {company_name}.'\n",
    "                    f'I would love to set up a time to chat to learn more about your experiences at your company. I have attached my resume for your reference. Please let me know if you are available as I am happy to work around your schedule to find a time to speak!'\n",
    "                    f'Thank gonna you for your time and I look forward to hearing from you!'\n",
    "                    f''\n",
    "                    f'Best regards,'\n",
    "                    f'{your_name}')\n",
    "    \n",
    "    # case for the type of email\n",
    "    elif email_type == ('school'):\n",
    "        template = (f'Hi {recepient_name},'\n",
    "                    f'I hope you are doing well! A quick introduction, my name is {your_name} and I am currently a rising senior studying {your_field}. I noticed you are a fellow alumni member of {your_university} so I was very excited to reach out!'\n",
    "                    f'I wanted to reach out because I am interested in the {your_field} field and to learn more about your role & career path at as a {position_name} at {company_name}.'\n",
    "                    f'I would love to set up a time to chat to learn more about your experiences at your company. I have attached my resume for your reference. Please let me know if you are available as I am happy to work around your schedule to find a time to speak!'\n",
    "                    f'Thank you for your time and I look forward to hearing from you!'\n",
    "                    f''\n",
    "                    f'Best regards,'\n",
    "                    f'{your_name}')\n",
    "    else:\n",
    "        print('Choose a Valid Email Type')\n",
    "    \n",
    "    return template\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:35:57.972128Z",
     "start_time": "2025-04-23T00:35:14.125814Z"
    }
   },
   "id": "b7b99677248300e3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Hi Dave,I hope you are doing well! A quick introduction, my name is Aaroh Jugulum and I am currently a rising senior at Northeastern University studying Data Science & Mathematics. I wanted to reach out because I am interested in the Data Science & Mathematics field and to learn more about your role & career path at as a Northeastern University at Volunteer.I would love to set up a time to chat to learn more about your experiences at your company. I have attached my resume for your reference. Please let me know if you are available as I am happy to work around your schedule to find a time to speak!Thank gonna you for your time and I look forward to hearing from you!Best regards,Aaroh Jugulum'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = generate_email('Aaroh Jugulum', 'Data Science & Mathematics', 'Northeastern University', 'Dave', \n",
    "                          position_name, company_name, 'general')\n",
    "\n",
    "# def a set of stop words \n",
    "stop_words = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"you\", \"your\", \"he\", \"his\", \"she\", \"her\", \"it\", \"its\"])\n",
    "\n",
    "# clean text manually\n",
    "def clean_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words] \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "template_clean = clean_text(template)\n",
    "template"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:07.794551Z",
     "start_time": "2025-04-23T00:36:07.789782Z"
    }
   },
   "id": "d7c94b9316c57e3e",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'hi hope are doing a quick name is aaroh jugulum and am currently a rising senior at northeastern university studying data science wanted to reach out because am interested in the data science mathematics field and to learn more about role career path at as a northeastern university at would love to set up a time to chat to learn more about experiences at have attached resume for please let know if are available as am happy to work around schedule to find a time to gonna for time and look forward to hearing from jugulum'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# def a set of stop words \n",
    "stop_words = set([\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"you\", \"your\", \"he\", \"his\", \"she\", \"her\", \"it\", \"its\"])\n",
    "\n",
    "# clean text manually\n",
    "def clean_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words] \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "template_clean = clean_text(template)\n",
    "template_clean"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:09.051676Z",
     "start_time": "2025-04-23T00:36:09.040669Z"
    }
   },
   "id": "7e313917819767b7",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "# helper functions\n",
    "def sentance_count(text):\n",
    "    sentance_list = list(text.split('.'))\n",
    "    sentance_count = len(sentance_list)\n",
    "    return sentance_count\n",
    "\n",
    "def wordy_char_count(text):\n",
    "    sentences = re.split(r'[.!?]', text) \n",
    "    over_count = sum(1 for sentence in sentences if len(sentence.strip()) > 150)\n",
    "    return over_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:10.235554Z",
     "start_time": "2025-04-23T00:36:10.228136Z"
    }
   },
   "id": "b11ea15d6def9514",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.2\n",
      "8.2\n",
      "8.78\n",
      "10.7\n",
      "8.1\n",
      "7.84\n",
      "8.43\n"
     ]
    }
   ],
   "source": [
    "print(textstat.flesch_reading_ease(template))  # Higher score = easier to read\n",
    "print(textstat.flesch_kincaid_grade(template))  # U.S. school grade level\n",
    "print(textstat.gunning_fog(template))  # Complexity based on word length & sentences\n",
    "print(textstat.smog_index(template))  # Measures polysyllabic words (ideal for short texts)\n",
    "print(textstat.automated_readability_index(template))  # Uses characters per word for grade level\n",
    "print(textstat.dale_chall_readability_score(template))  # Uses a list of \"common\" words for difficulty\n",
    "print(textstat.reading_time(template))  # Estimated reading time in seconds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:10.811692Z",
     "start_time": "2025-04-23T00:36:10.804667Z"
    }
   },
   "id": "b3b7c8dbd9845683",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def analyze_readability(text):\n",
    "    scores = {\n",
    "        \"Flesch-Kincaid Grade Level\": textstat.flesch_kincaid_grade(text),\n",
    "        \"Gunning Fog Index\": textstat.gunning_fog(text),\n",
    "        \"Dale-Chall Readability Score\": textstat.dale_chall_readability_score(text),\n",
    "        \"Flesch Reading Ease\": textstat.flesch_reading_ease(text)\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "\n",
    "def analyze_professionalism(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = analyzer.polarity_scores(text)[\"compound\"] \n",
    "\n",
    "    doc = nlp(text)\n",
    "    complex_words = sum(1 for token in doc if token.is_alpha and len(token.text) > 12) \n",
    "    num_sentences = len(list(doc.sents))\n",
    "    avg_sentence_length = len(text.split()) / num_sentences if num_sentences > 0 else 1\n",
    "    over_count = wordy_char_count(template) \n",
    "    sentance_counts = sentance_count(template)\n",
    "  \n",
    "    informal_words = {\"gonna\", \"wanna\", \"lemme\", \"gotta\", \"bro\", \"dude\", \"lol\", \"omg\", \"lmao\", \"cuz\"\n",
    "                      'love', 'very'}\n",
    "    \n",
    "    overly_formal_words = {\"utilize\", \"commence\", \"terminate\", \"ascertain\", \"disseminate\", \"facilitate\", \"execute\",\n",
    "                           \"expedite\", \"engender\", \"convey\"}\n",
    "    \n",
    "    hedging_words = {\"maybe\",\"probably\",\"possibly\",\"perhaps\",\"seems\",\"appears\",\"might\",\"could\",\"somewhat\",\n",
    "                     \"relatively\"}\n",
    "\n",
    "\n",
    "    # count the number of types of instances \n",
    "    informal_instances = list(1 for i in text.lower().split() if i in informal_words)\n",
    "    informal_count = sum(1 for i in text.lower().split() if i in informal_words)\n",
    "    overly_formal_instances = list(1 for i in text.lower().split() if i in overly_formal_words)\n",
    "    overly_formal_count = sum(1 for i in text.lower().split() if i in overly_formal_words)\n",
    "    hedging_instances = list(1 for i in text.lower().split() if i in hedging_words)\n",
    "    hedging_count = sum(1 for i in text.lower().split() if i in hedging_words)\n",
    "   \n",
    "   # calc the scores \n",
    "    calc_score = (\n",
    "        (1 - abs(sentiment_score)) * 40  \n",
    "        + (1 - (complex_words / max(len(text.split()), 1))) * 20 \n",
    "        + (1 - informal_count / max(len(text.split()), 1)) * 20  \n",
    "        + (1 if avg_sentence_length > 8 else 0) * 20 \n",
    "        + (1 - over_count / sentance_counts) * 20\n",
    "        + (1- overly_formal_count / max(len(text.split()), 1)) * 20\n",
    "        + (1- hedging_count / max(len(text.split()), 1)) * 20\n",
    "    )\n",
    "    #print((complex_words / max(len(text.split()), 1)))\n",
    "    #print((informal_count / max(len(text.split()), 1)))\n",
    "    #print((hedging_count / max(len(text.split()), 1)))\n",
    "    #print((overly_formal_count / max(len(text.split()), 1)))\n",
    "    calc_score = min(max(calc_score, 0), 100)\n",
    "    \n",
    "    ease_read = textstat.flesch_reading_ease(template)\n",
    "    polly_syllabic = textstat.smog_index(template)\n",
    "    time_to_read = textstat.reading_time(template)\n",
    "    \n",
    "    # define length scoring \n",
    "    if time_to_read > 8:\n",
    "        calc_score += -2\n",
    "        print('Takes too long to read this email, recipient will lose interest')\n",
    "    elif polly_syllabic > 10:\n",
    "        calc_score += -2\n",
    "    else:\n",
    "        calc_score = calc_score\n",
    "        print('Too many words that are not good for short text')\n",
    "    \n",
    "    \n",
    "    # define the readability scores\n",
    "    scores = analyze_readability(template)\n",
    "    vals = list(scores.values())\n",
    "    if vals[0] > 8:\n",
    "        calc_score += -2\n",
    "    elif vals[1] < 7:\n",
    "        calc_score += -2\n",
    "    elif vals[2] < 8:\n",
    "        calc_score += -2\n",
    "    elif vals[3] < 70:\n",
    "        calc_score += -2\n",
    "    else:\n",
    "        calc_score = calc_score\n",
    "    \n",
    "    return calc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:12.261647Z",
     "start_time": "2025-04-23T00:36:11.280464Z"
    }
   },
   "id": "29542e9389a05076",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes too long to read this email, recipient will lose interest\n"
     ]
    },
    {
     "data": {
      "text/plain": "96"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_scores = analyze_professionalism(template)\n",
    "calc_scores "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:12.336342Z",
     "start_time": "2025-04-23T00:36:12.261586Z"
    }
   },
   "id": "846ce651ac380b6f",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_error_sentance(template):\n",
    "    template_list = template.lower().split('.')\n",
    "    \n",
    "    # define the list of words \n",
    "    informal_words = {\"gonna\", \"wanna\", \"lemme\", \"gotta\", \"bro\", \"dude\", \"lol\", \"omg\", \"lmao\", \"cuz\"\n",
    "                          'love', 'very'}\n",
    "        \n",
    "    overly_formal_words = {\"utilize\", \"commence\", \"terminate\", \"ascertain\", \"disseminate\", \"facilitate\", \"execute\",\n",
    "                               \"expedite\", \"engender\", \"convey\"}\n",
    "        \n",
    "    hedging_words = {\"maybe\",\"probably\",\"possibly\",\"perhaps\",\"seems\",\"appears\",\"might\",\"could\",\"somewhat\",\n",
    "                         \"relatively\"}\n",
    "    \n",
    "    # init the analyzer object \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # init the dict \n",
    "    scores_dict = dict()\n",
    "    \n",
    "    # loop through each sentance and give a score\n",
    "    for idx, i in enumerate(template_list):\n",
    "        \n",
    "        # sentiment score for each sentence \n",
    "        sentiment_score = analyzer.polarity_scores(i)[\"compound\"] \n",
    "        \n",
    "        # init a nlp object to perform further analysis in the future \n",
    "        doc = nlp(i)\n",
    "        \n",
    "        # types of instances \n",
    "        informal_instances = list(j for j in i.lower().split() if j in informal_words)\n",
    "        overly_formal_instances = list(j for j in i.lower().split() if j in overly_formal_words)\n",
    "        hedging_instances = list(j for j in i.lower().split() if j in hedging_words)\n",
    "        \n",
    "        # counts\n",
    "        informal_count = sum(1 for j in i.lower().split() if j in informal_words) \n",
    "        overly_formal_count = sum(1 for j in i.lower().split() if j in overly_formal_words)\n",
    "        hedging_count = sum(1 for j in i.lower().split() if j in hedging_words)\n",
    "        \n",
    "        # sentence score \n",
    "        sentence_score = ((1 - abs(sentiment_score)) * 40\n",
    "        + (1 - informal_count / max(len(i.split()), 1)) * 20  \n",
    "        + (1- overly_formal_count / max(len(i.split()), 1)) * 20\n",
    "        + (1- hedging_count / max(len(i.split()), 1)) * 20\n",
    "        )\n",
    "       \n",
    "        # round\n",
    "        sentence_score = round(sentence_score, 2)\n",
    "        \n",
    "        # update the dict\n",
    "        scores_dict[idx] = (sentence_score, sentiment_score, informal_count, overly_formal_count, hedging_count)\n",
    "        \n",
    "    return scores_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:12.924240Z",
     "start_time": "2025-04-23T00:36:12.920835Z"
    }
   },
   "id": "3e6d892d6aba7b6f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def instance_sentance(template):\n",
    "    template_list = template.lower().split('.')\n",
    "    \n",
    "    # define the list of words \n",
    "    informal_words = {\"gonna\", \"wanna\", \"lemme\", \"gotta\", \"bro\", \"dude\", \"lol\", \"omg\", \"lmao\", \"cuz\"\n",
    "                          'love', 'very'}\n",
    "        \n",
    "    overly_formal_words = {\"utilize\", \"commence\", \"terminate\", \"ascertain\", \"disseminate\", \"facilitate\", \"execute\",\n",
    "                               \"expedite\", \"engender\", \"convey\"}\n",
    "        \n",
    "    hedging_words = {\"maybe\",\"probably\",\"possibly\",\"perhaps\",\"seems\",\"appears\",\"might\",\"could\",\"somewhat\",\n",
    "                         \"relatively\"}\n",
    "    \n",
    "    # loop through each sentance and give a score\n",
    "    for idx, i in enumerate(template_list):\n",
    "        # types of instances and append to the list \n",
    "        informal_instances = list(j for j in i.lower().split() if j in informal_words)\n",
    "        overly_formal_instances = list(j for j in i.lower().split() if j in overly_formal_words)\n",
    "        hedging_instances = list(j for j in i.lower().split() if j in hedging_words)\n",
    "    \n",
    "    \n",
    "    return informal_instances, overly_formal_instances, hedging_instances\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:13.506264Z",
     "start_time": "2025-04-23T00:36:13.500851Z"
    }
   },
   "id": "1f89d4d93a7d7ca4",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def give_feedback_weak(template):\n",
    "    sentence_score = count_error_sentance(template)\n",
    "    \n",
    "    weak_list_sentences = list()\n",
    "    for i in sentence_score.keys():\n",
    "        critique_list = list(sentence_score[i])\n",
    "        if critique_list[0] < 75:\n",
    "            weak_list_sentences.append(i)\n",
    "            \n",
    "    informal_instance = instance_sentance(template)[0]\n",
    "    overly_formal_instance = instance_sentance(template)[1]\n",
    "    hedging_instance = instance_sentance(template)[2]\n",
    "    \n",
    "    crit_dict = dict()\n",
    "    for i in weak_list_sentences:\n",
    "        critique_list_weak = list(sentence_score[i])\n",
    "        crit_1 = crit_2 = crit_3 = crit_4 = None\n",
    "        if critique_list_weak[1] < 0.5:\n",
    "            crit_1 = (f'You are not enthusiastic enough the audience will be disengaged, try using more reinforcing and '\n",
    "                  'positive language within the email.')\n",
    "        elif critique_list_weak[2] > 0:\n",
    "            crit_2 = (f'You are using some informal language in this sentence. These are the instance(s): {informal_instance}')\n",
    "        elif critique_list_weak[3] > 0:\n",
    "            crit_3 = (f'You are too formal, you want to keep the language digestible.These are the instance(s): {overly_formal_instance}')\n",
    "        elif critique_list_weak[4] > 0:\n",
    "            crit_4 = (f'You are using words that reduce your credibility, you want to be firm and direct. These are the instance(s): {hedging_instance}')\n",
    "        \n",
    "        crit_dict[i] = tuple(j for j in [crit_1, crit_2, crit_3, crit_4] if j != None)\n",
    "        \n",
    "        non_empty_crit = {k: v for k, v in crit_dict.items() if v}\n",
    "        \n",
    "        # return a message as the output \n",
    "        message_list = list()\n",
    "        for i in non_empty_crit.keys():\n",
    "            message = f'Sentence {i} has the issue. {non_empty_crit[i][0]}'\n",
    "            message_list.append(message)\n",
    "    \n",
    "    return message_list       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:14.304065Z",
     "start_time": "2025-04-23T00:36:14.289416Z"
    }
   },
   "id": "12acfcef977a19f5",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[\"Sentence 4 has the issue. You are using some informal language in this sentence. These are the instance(s): ['gonna']\"]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = give_feedback_weak(template)\n",
    "message "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T00:36:15.610091Z",
     "start_time": "2025-04-23T00:36:15.547240Z"
    }
   },
   "id": "aed7024627cb47a7",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-04T22:20:40.211907Z",
     "start_time": "2025-05-04T22:20:40.206353Z"
    }
   },
   "id": "c66c4c4a3e7a6ae8",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c0c73b9c454278d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
